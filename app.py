import streamlit as st
import nltk
import matplotlib.pyplot as plt
from nltk.util import ngrams
from nltk.lm.preprocessing import padded_everygram_pipeline
from nltk.lm import MLE
from nltk.corpus import stopwords
import string

# Download necessary NLTK resources
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

try:
    nltk.data.find('corpora/brown')
except LookupError:
    nltk.download('brown')

# Preprocess the input text
def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation and not token.isdigit()]
    return tokens

# Plot the most common words
def plot_most_common_words(text):
    tokens = preprocess_text(text)
    word_freq = nltk.FreqDist(tokens)
    most_common_words = word_freq.most_common(10)
    if not most_common_words:
        st.info("No common words to display.")
        return
    words, counts = zip(*most_common_words)
    plt.figure(figsize=(10, 6))
    plt.bar(words, counts)
    plt.xlabel('Words')
    plt.ylabel('Frequency')
    plt.title('Most Common Words')
    plt.xticks(rotation=45)
    st.pyplot(plt.gcf())
    plt.close()

# Plot repeated words
def plot_repeated_words(text):
    tokens = preprocess_text(text)
    word_freq = nltk.FreqDist(tokens)
    repeated_words = [word for word, count in word_freq.items() if count > 1][:10]
    if not repeated_words:
        st.info("No repeated words to display.")
        return
    words, counts = zip(*[(word, word_freq[word]) for word in repeated_words])
    plt.figure(figsize=(10, 6))
    plt.bar(words, counts)
    plt.xlabel('Words')
    plt.ylabel('Frequency')
    plt.title('Repeated Words')
    plt.xticks(rotation=45)
    st.pyplot(plt.gcf())
    plt.close()

# Calculate perplexity
def calculate_perplexity(text, model):
    tokens = preprocess_text(text)
    if not tokens:
        return float('inf')
    padded_tokens = ['<s>'] + tokens + ['</s>']
    ngrams_sequence = list(ngrams(padded_tokens, model.order))
    return model.perplexity(ngrams_sequence)

# Calculate burstiness
def calculate_burstiness(text):
    tokens = preprocess_text(text)
    word_freq = nltk.FreqDist(tokens)
    if len(word_freq) == 0:
        return 0.0
    avg_freq = sum(word_freq.values()) / len(word_freq)
    variance = sum((freq - avg_freq) ** 2 for freq in word_freq.values()) / len(word_freq)
    burstiness_score = variance / (avg_freq ** 2) if avg_freq != 0 else 0.0
    return burstiness_score

# Determine if text is likely generated
def is_generated_text(perplexity, burstiness_score):
    if perplexity < 200 and burstiness_score < 1:
        return "âœ… Likely generated by a language model"
    else:
        return "ðŸ§  Not likely generated by a language model"

# Load or cache the n-gram model
@st.cache_resource
def get_ngram_model(n=2):
    tokens = [word.lower() for word in nltk.corpus.brown.words()]
    train_data, padded_vocab = padded_everygram_pipeline(n, tokens)
    model = MLE(n)
    model.fit(train_data, padded_vocab)
    return model

# Main Streamlit app logic
def main():
    st.title("ðŸ§ª Language Model Text Analysis")
    text = st.text_area("Enter the text you want to analyze", height=200)

    if st.button("ðŸ” Analyze"):
        if text:
            model = get_ngram_model(2)  # Bigram model
            perplexity = calculate_perplexity(text, model)
            burstiness_score = calculate_burstiness(text)

            st.write("ðŸ”¢ **Perplexity**:", round(perplexity, 2))
            st.write("ðŸ“Š **Burstiness Score**:", round(burstiness_score, 4))

            result = is_generated_text(perplexity, burstiness_score)
            st.subheader("ðŸ”Ž Conclusion:")
            if "Likely" in result:
                st.success(result)
            else:
                st.info(result)

            with st.expander("ðŸ“ˆ Show Most Common Words"):
                plot_most_common_words(text)

            with st.expander("ðŸ” Show Repeated Words"):
                plot_repeated_words(text)
        else:
            st.warning("âš ï¸ Please enter some text to analyze.")

# Run the app
if __name__ == "__main__":
    main()
